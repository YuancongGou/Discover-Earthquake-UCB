{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:24:30.211431Z",
     "start_time": "2022-04-07T16:24:26.114500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import h5py\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import shutil\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D, Conv1D, MaxPooling1D, UpSampling1D, Flatten, Dropout, Reshape, GaussianNoise, Cropping2D \n",
    "from keras.layers import Bidirectional, BatchNormalization, ZeroPadding1D, ZeroPadding2D, Conv2DTranspose\n",
    "from keras.models import Model, Sequential\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Layer, InputSpec\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, EarlyStopping\n",
    "from keras.initializers import VarianceScaling\n",
    "from keras.callbacks import CSVLogger\n",
    "from scipy.optimize import linear_sum_assignment as linear_assignment\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import savefig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:24:36.725196Z",
     "start_time": "2022-04-07T16:24:30.225496Z"
    }
   },
   "outputs": [],
   "source": [
    "time = np.arange(0, 86.4, 0.00001);\n",
    "sine = np.sin(time)\n",
    "noise = np.random.normal(0,0.1,8640000)\n",
    "noisy_sine = sine + noise\n",
    "\n",
    "zeros = [0] * 8640000\n",
    "sine_noise_by_time = [[noisy_sine[i], zeros[i], zeros[i]] for i in range(len(noisy_sine))]\n",
    "\n",
    "stream = [noisy_sine, zeros, zeros]\n",
    "\n",
    "# step_size = 1000 # originally 16, try to increase to 1000 to represent 10 seconds\n",
    "# batched_stream_arr_by_time = [sine_noise_by_time[i:i + step_size] for i in range(0, len(sine_noise_by_time), step_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:24:56.045775Z",
     "start_time": "2022-04-07T16:24:55.357188Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "freq, time, stft = signal.stft(noisy_sine, padded=False, nperseg = 2000 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:25:26.738809Z",
     "start_time": "2022-04-07T16:25:14.836013Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stft_stream = np.asarray([np.asarray([np.asarray([stft[i][j], 0, 0]) for j in range(len(stft[i]))]) for i in range(len(stft))])\n",
    "# stft_stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:25:45.288463Z",
     "start_time": "2022-04-07T16:25:45.281524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stft_stream[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:26:04.000739Z",
     "start_time": "2022-04-07T16:26:03.997934Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_size = len(stft)\n",
    "step_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:26:22.643081Z",
     "start_time": "2022-04-07T16:26:22.639310Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8640"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stft[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### documentation: https://pytorch.org/docs/stable/nn.functional.html#torch.nn.functional.conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:18:51.998280Z",
     "start_time": "2022-04-07T16:18:51.995629Z"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = (len(stft[0]), 3, 1)\n",
    "batch_size = 150\n",
    "no_epochs = 5\n",
    "train_test_split = 0.3\n",
    "validation_split = 0.2\n",
    "verbosity = 1\n",
    "max_norm_value = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T07:04:11.459456Z",
     "start_time": "2022-04-07T07:04:11.390674Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 67501, 3, 8)       80        \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 67501, 3, 4)       292       \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 67501, 3, 2)       74        \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 67501, 3, 2)      38        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 67501, 3, 4)      76        \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 67501, 3, 8)      296       \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 67501, 3, 1)       73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 929\n",
      "Trainable params: 929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "# model.add(Conv1D(128, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform', input_shape=input_shape))\n",
    "# model.add(Conv1D(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Conv1DTranspose(32, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Conv1DTranspose(128, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='relu', kernel_initializer='he_uniform'))\n",
    "# model.add(Conv1D(1, kernel_size=3, kernel_constraint=max_norm(max_norm_value), activation='sigmoid', padding='same'))\n",
    "\n",
    "# inp = Input(shape)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(8, (3, 3), activation='relu', padding='same', input_shape=input_shape))\n",
    "# model.add(MaxPooling2D((10, 3), padding='same'))\n",
    "model.add(Conv2D(4, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((8, 1), padding='same'))\n",
    "model.add(Conv2D(2, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D((6, 1), padding='same'))\n",
    "\n",
    "model.add(Conv2DTranspose(2, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(UpSampling2D((6, 1)))\n",
    "model.add(Conv2DTranspose(4, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(UpSampling2D((8, 1)))\n",
    "model.add(Conv2DTranspose(8, (3, 3), activation='relu', padding='same'))\n",
    "# model.add(UpSampling2D((10, 3)))\n",
    "model.add(Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same'))\n",
    "\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:32:42.300005Z",
     "start_time": "2022-04-07T16:32:42.232273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 8640, 3, 1)]      0         \n",
      "                                                                 \n",
      " gaussian_noise_2 (GaussianN  (None, 8640, 3, 1)       0         \n",
      " oise)                                                           \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 8640, 3, 8)        80        \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 4320, 1, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 4320, 1, 4)        292       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2160, 1, 4)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 2160, 1, 2)        74        \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 1080, 1, 2)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2160)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 1080, 1, 2)        0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 1080, 1, 2)        38        \n",
      "                                                                 \n",
      " up_sampling2d_6 (UpSampling  (None, 2160, 1, 2)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 2160, 1, 4)        76        \n",
      "                                                                 \n",
      " up_sampling2d_7 (UpSampling  (None, 4320, 1, 4)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 4320, 1, 8)        296       \n",
      "                                                                 \n",
      " up_sampling2d_8 (UpSampling  (None, 8640, 3, 8)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 8640, 3, 1)        73        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 929\n",
      "Trainable params: 929\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(len(stft[0]), 3, 1))  \n",
    "\n",
    "e = GaussianNoise(0.2)(inp)\n",
    "# e = Cropping2D(cropping=((0, 0), (1, 0)), data_format = None)(e)\n",
    "\n",
    "e = Conv2D(8, (3, 3), activation='selu', padding='same')(e)\n",
    "e = MaxPooling2D((2, 3), padding='same')(e)\n",
    "e = Conv2D(4, (3, 3), activation='selu', padding='same')(e)\n",
    "e = MaxPooling2D((2, 1), padding='same')(e)\n",
    "e = Conv2D(2, (3, 3), activation='selu', padding='same')(e)\n",
    "e = MaxPooling2D((2, 1), padding='same')(e)\n",
    "\n",
    "shape_before_flattening = K.int_shape(e)\n",
    "encoded = Flatten()(e)\n",
    "# encoded = e\n",
    "d = Reshape(shape_before_flattening[1:])(encoded)\n",
    "# d = encoded\n",
    "\n",
    "d = Conv2D(2, (3, 3), activation='selu', padding='same')(d)\n",
    "d = UpSampling2D((2, 1))(d)\n",
    "d = Conv2D(4, (3, 3), activation='selu', padding='same')(d)\n",
    "d = UpSampling2D((2, 1))(d)\n",
    "d = Conv2D(8, (3, 3), activation='selu', padding='same')(d)\n",
    "d = UpSampling2D((2, 3))(d)\n",
    "# d = ZeroPadding2D((0, 1))(d)\n",
    "# d = Cropping2D(cropping=((0, 0), (2499, 0)), data_format = None)(d)\n",
    "\n",
    "decoded = Conv2D(1, (3, 3), padding='same')(d)\n",
    "\n",
    "\n",
    "autoencoder = Model(inputs=inp, outputs=decoded, name='autoencoder')\n",
    "encoder = Model(inputs=inp, outputs=encoded, name='encoder')\n",
    "\n",
    "autoencoder.compile(loss=\"mse\", optimizer='adam')\n",
    "csv_logger = CSVLogger('pretrain_log.csv')\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:33:13.811712Z",
     "start_time": "2022-04-07T16:33:00.331779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "8/8 [==============================] - 7s 802ms/step - loss: 2.9787e-04\n",
      "Epoch 2/2\n",
      "8/8 [==============================] - 6s 804ms/step - loss: 2.2822e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9f7f9772e0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.fit(stft_stream, stft_stream, batch_size=128, epochs=2, callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-04-07T16:33:15.580Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = encoder.predict(stft_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:31:58.834852Z",
     "start_time": "2022-04-07T16:31:58.815848Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-9ebe25131576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \"\"\"\n\u001b[0;32m-> 1139\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m   1140\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    784\u001b[0m                 ) from e\n\u001b[1;32m    785\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0;34m\"Found array with dim %d. %s expected <= 2.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "kmeans = KMeans(n_clusters = 2)\n",
    "kmeans.fit(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T16:29:47.818169Z",
     "start_time": "2022-04-07T16:29:47.729875Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...Finetuning...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"clustering\" (type ClusteringLayer).\n\nin user code:\n\n    File \"<ipython-input-14-504be8e1be60>\", line 22, in call  *\n        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n\n    ValueError: Dimensions must be equal, but are 2 and 1080 for '{{node clustering/sub}} = Sub[T=DT_FLOAT](clustering/ExpandDims, clustering/sub/ReadVariableOp)' with input shapes: [?,1,1080,1,2], [2,1080].\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1080, 1, 2), dtype=float32)\n  • kwargs={'training': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-504be8e1be60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'...Finetuning...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mclustering_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClusteringLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'clustering'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclustering_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    697\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m           \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"clustering\" (type ClusteringLayer).\n\nin user code:\n\n    File \"<ipython-input-14-504be8e1be60>\", line 22, in call  *\n        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n\n    ValueError: Dimensions must be equal, but are 2 and 1080 for '{{node clustering/sub}} = Sub[T=DT_FLOAT](clustering/ExpandDims, clustering/sub/ReadVariableOp)' with input shapes: [?,1,1080,1,2], [2,1080].\n\n\nCall arguments received:\n  • inputs=tf.Tensor(shape=(None, 1080, 1, 2), dtype=float32)\n  • kwargs={'training': 'None'}"
     ]
    }
   ],
   "source": [
    "class ClusteringLayer(Layer):\n",
    "    def __init__(self, n_clusters, weights=None, alpha=1.0, **kwargs):\n",
    "        if 'input_shape' not in kwargs and 'input_dim' in kwargs:\n",
    "            kwargs['input_shape'] = (kwargs.pop('input_dim'),)\n",
    "        super(ClusteringLayer, self).__init__(**kwargs)\n",
    "        self.n_clusters = n_clusters\n",
    "        self.alpha = alpha\n",
    "        self.initial_weights = weights\n",
    "        self.input_spec = InputSpec(ndim=4)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 4\n",
    "        input_dim = input_shape[1]\n",
    "        self.input_spec = InputSpec(dtype=K.floatx(), shape=(None, input_dim))\n",
    "        self.clusters = self.add_weight(shape=(self.n_clusters, input_dim), initializer='glorot_uniform', name='clusters')\n",
    "        if self.initial_weights is not None:\n",
    "            self.set_weights(self.initial_weights)\n",
    "            del self.initial_weights\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        q = 1.0 / (1.0 + (K.sum(K.square(K.expand_dims(inputs, axis=1) - self.clusters), axis=2) / self.alpha))\n",
    "        q **= (self.alpha + 1.0) / 2.0\n",
    "        q = K.transpose(K.transpose(q) / K.sum(q, axis=1)) \n",
    "        return q\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        assert input_shape and len(input_shape) == 4\n",
    "        return input_shape[0], self.n_clusters\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'n_clusters': self.n_clusters}\n",
    "        base_config = super(ClusteringLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "print('...Finetuning...')\n",
    "n_clusters = 2\n",
    "clustering_layer = ClusteringLayer(n_clusters, name='clustering')(encoder.output)\n",
    "model = Model(inputs=[encoder.input], outputs=[clustering_layer, autoencoder.output])\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam')\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "# from IPython.display import Image\n",
    "# Image(filename='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
